{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf283f7-9569-482e-acbb-bfc3763a195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from agents.actor_critic import A2C\n",
    "from networks.a2c.actor import Actor\n",
    "from networks.a2c.critic import Critic\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a2c0d6-9cc9-47bf-a000-0c7a486538e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6935c8c4-da6f-40a4-8f5e-dd61abde31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model = Actor(\n",
    "    state_dim=env.observation_space.shape[0],\n",
    "    action_dim=env.action_space.n,\n",
    ")\n",
    "critic_model = Critic(state_dim=env.observation_space.shape[0])\n",
    "a2c = A2C(\n",
    "    env=env, \n",
    "    actor=actor_model,\n",
    "    critic=critic_model,\n",
    "    n_actns=env.action_space.n,\n",
    "    actor_optmz=torch.optim.Adam(actor_model.parameters(), lr=0.01),\n",
    "    critic_optmz=torch.optim.Adam(critic_model.parameters(), lr=0.01),\n",
    "    hyprprms={\n",
    "        'gamma': 0.995,\n",
    "    },\n",
    "    log_freq=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c40ea5-1c50-4b1b-914d-7aa5f3b2b616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Loss: 1.331682529833601, Avg. Reward: -302.21458918575036\n",
      "Episode: 300, Loss: 0.2519504735297385, Avg. Reward: -260.83467229224925\n",
      "Episode: 600, Loss: 0.1106633699286725, Avg. Reward: -1068.0314305551747\n",
      "Episode: 900, Loss: 0.06283729166852627, Avg. Reward: -627.3762311537967\n",
      "Episode: 1200, Loss: 0.03215111832444224, Avg. Reward: -785.1985028549698\n",
      "Episode: 1500, Loss: 0.031966482161484004, Avg. Reward: -451.6824461062926\n",
      "Episode: 1800, Loss: 0.12409709852947984, Avg. Reward: -2036.5139378050021\n",
      "Episode: 2100, Loss: 0.08364662381019568, Avg. Reward: -850.1055932644175\n",
      "Episode: 2400, Loss: 0.040047208573154074, Avg. Reward: -779.6604924973996\n",
      "Episode: 2700, Loss: 0.04739678060381971, Avg. Reward: -437.604615445344\n",
      "Episode: 3000, Loss: 0.06796326984266797, Avg. Reward: -678.4059284310729\n",
      "Episode: 3300, Loss: 0.006029107522937751, Avg. Reward: -390.5906596290715\n",
      "Episode: 3600, Loss: 0.03061930929103058, Avg. Reward: -973.4365613066574\n",
      "Episode: 3900, Loss: 0.04621463021314842, Avg. Reward: -631.2341972187928\n",
      "Episode: 4200, Loss: 0.15404903443400664, Avg. Reward: -1820.7471550673995\n",
      "Episode: 4500, Loss: 0.04974062322754021, Avg. Reward: -518.0390535685503\n",
      "Episode: 4800, Loss: 0.008045823124769728, Avg. Reward: -473.6171191230699\n"
     ]
    }
   ],
   "source": [
    "a2c.run(5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
