{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf283f7-9569-482e-acbb-bfc3763a195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent directory to path: enable import from parent dir\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from agents.actor_critic import A2C\n",
    "from networks.a2c.actor import Actor\n",
    "from networks.a2c.critic import Critic\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a2c0d6-9cc9-47bf-a000-0c7a486538e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6935c8c4-da6f-40a4-8f5e-dd61abde31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_model = Actor(\n",
    "    state_dim=env.observation_space.shape[0],\n",
    "    action_dim=env.action_space.n,\n",
    ")\n",
    "critic_model = Critic(state_dim=env.observation_space.shape[0])\n",
    "a2c = A2C(\n",
    "    env=env, \n",
    "    actor=actor_model,\n",
    "    critic=critic_model,\n",
    "    n_actns=env.action_space.n,\n",
    "    actor_optmz=torch.optim.Adam(actor_model.parameters(), lr=0.01),\n",
    "    critic_optmz=torch.optim.Adam(critic_model.parameters(), lr=0.01),\n",
    "    hyprprms={\n",
    "        'gamma': 0.995,\n",
    "    },\n",
    "    log_freq=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c40ea5-1c50-4b1b-914d-7aa5f3b2b616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Loss: 0.7179769088709179, Avg. Reward: -102.64780888504694\n",
      "Episode: 100, Loss: 0.9291630084039133, Avg. Reward: -81.96022538420772\n",
      "Episode: 200, Loss: 0.19889938159475107, Avg. Reward: -132.82340153655622\n",
      "Episode: 300, Loss: 0.9248855003462119, Avg. Reward: -96.2321630574747\n",
      "Episode: 400, Loss: 0.8430181259324453, Avg. Reward: -13.43331036885236\n",
      "Episode: 500, Loss: 0.34366420045834895, Avg. Reward: -10.128628490185875\n",
      "Episode: 600, Loss: 0.9182567154630386, Avg. Reward: -113.19364130077234\n",
      "Episode: 700, Loss: 0.7259756551603703, Avg. Reward: -171.32765335663944\n",
      "Episode: 800, Loss: 0.2136178680868966, Avg. Reward: -91.53432316615493\n",
      "Episode: 900, Loss: 0.2300156010147279, Avg. Reward: -325.89686288076456\n"
     ]
    }
   ],
   "source": [
    "a2c.run(5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
